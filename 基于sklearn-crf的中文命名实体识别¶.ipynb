{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6602ae7a-32d9-4158-97d4-be06148b66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "import joblib\n",
    "import yaml\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cea18ca-4ed8-4373-b4b5-7d15aae09153",
   "metadata": {},
   "source": [
    "## 通用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ec326f-48a3-461c-9349-25b0361906dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    data = list()\n",
    "    data_sent_with_label = list()\n",
    "    with open(data_path, mode='r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip() == \"\":\n",
    "                data.append(data_sent_with_label.copy())\n",
    "                data_sent_with_label.clear()\n",
    "            else:\n",
    "                data_sent_with_label.append(tuple(line.strip().split(\" \")))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed9860-0602-4c61-9855-2a6fcf8f9bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eef6be-ca98-4e0a-96ae-1fca7355630e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f49ed0a-def3-43c6-a59f-c8b52673178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word': word,\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        # 'word.isalpha()': word.isalpha()\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        words = word1 + word\n",
    "        features.update({\n",
    "            '-1:word': word1,\n",
    "            '-1:words': words,\n",
    "            '-1:word.isdigit()': word1.isdigit(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i > 1:\n",
    "        word2 = sent[i-2][0]\n",
    "        word1 = sent[i-1][0]\n",
    "        words = word1 + word2 + word\n",
    "        features.update({\n",
    "            '-2:word': word2,\n",
    "            '-2:words': words,\n",
    "            '-3:word.isdigit()': word1.isdigit(),\n",
    "        })\n",
    "\n",
    "    if i > 2:\n",
    "        word3 = sent[i - 3][0]\n",
    "        word2 = sent[i - 2][0]\n",
    "        word1 = sent[i - 1][0]\n",
    "        words = word1 + word2 + word3 + word\n",
    "        features.update({\n",
    "            '-3:word': word3,\n",
    "            '-3:words': words,\n",
    "            '-3:word.isdigit()': word1.isdigit(),\n",
    "        })\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        words = word1 + word\n",
    "        features.update({\n",
    "            '+1:word': word1,\n",
    "            '+1:words': words,\n",
    "            '+1:word.isdigit()': word1.isdigit(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    if i < len(sent)-2:\n",
    "        word2 = sent[i + 2][0]\n",
    "        word1 = sent[i + 1][0]\n",
    "        words = word + word1 + word2\n",
    "        features.update({\n",
    "            '+2:word': word2,\n",
    "            '+2:words': words,\n",
    "            '+2:word.isdigit()': word2.isdigit(),\n",
    "        })\n",
    "\n",
    "    if i < len(sent)-3:\n",
    "        word3 = sent[i + 3][0]\n",
    "        word2 = sent[i + 2][0]\n",
    "        word1 = sent[i + 1][0]\n",
    "        words = word + word1 + word2 + word3\n",
    "        features.update({\n",
    "            '+3:word': word3,\n",
    "            '+3:words': words,\n",
    "            '+3:word.isdigit()': word3.isdigit(),\n",
    "        })\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3006b5e2-6494-4300-b232-62b041afd9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [ele[-1] for ele in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95f1ff6-0939-4273-a207-3971859c127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5021 5021 5021\n",
      "(002399)调研地点\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NOUN', 'I-NOUN', 'I-NOUN', 'I-NOUN']\n"
     ]
    }
   ],
   "source": [
    "train=load_data('data/train.txt')\n",
    "valid=load_data('data/train.txt')\n",
    "test=load_data('data/train.txt')\n",
    "print(len(train),len(valid),len(test))\n",
    "\n",
    "sample_text=''.join([c[0] for c in train[0]])\n",
    "sample_tags=[c[1] for c in train[0]]\n",
    "print(sample_text)\n",
    "print(sample_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8193ae0d-0926-41b8-a84a-f9ed26a2cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = [sent2features(s) for s in train]\n",
    "y_train = [sent2labels(s) for s in train]\n",
    "\n",
    "X_dev = [sent2features(s) for s in valid]\n",
    "y_dev = [sent2labels(s) for s in valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67761997-2225-46e5-8072-6150b7bc2067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5021/5021 [00:00<00:00, 6313.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 136895\n",
      "Seconds required: 0.314\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.250000\n",
      "c2: 0.018000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.05  loss=44249.62 active=134918 feature_norm=1.00\n",
      "Iter 2   time=0.03  loss=38282.47 active=133008 feature_norm=1.56\n",
      "Iter 3   time=0.03  loss=31759.15 active=133350 feature_norm=2.29\n",
      "Iter 4   time=0.03  loss=25928.61 active=133524 feature_norm=3.11\n",
      "Iter 5   time=0.03  loss=21637.99 active=134347 feature_norm=4.38\n",
      "Iter 6   time=0.03  loss=19954.04 active=134720 feature_norm=5.45\n",
      "Iter 7   time=0.03  loss=18085.24 active=134902 feature_norm=6.37\n",
      "Iter 8   time=0.03  loss=16523.11 active=134288 feature_norm=7.82\n",
      "Iter 9   time=0.03  loss=15493.01 active=132908 feature_norm=9.16\n",
      "Iter 10  time=0.03  loss=14558.04 active=133022 feature_norm=10.74\n",
      "Iter 11  time=0.03  loss=13760.75 active=130721 feature_norm=12.67\n",
      "Iter 12  time=0.03  loss=12794.44 active=128820 feature_norm=14.01\n",
      "Iter 13  time=0.03  loss=11815.06 active=126002 feature_norm=15.39\n",
      "Iter 14  time=0.03  loss=10709.99 active=123625 feature_norm=17.58\n",
      "Iter 15  time=0.03  loss=9715.97  active=120075 feature_norm=18.94\n",
      "Iter 16  time=0.03  loss=8911.64  active=113425 feature_norm=21.07\n",
      "Iter 17  time=0.03  loss=8339.25  active=106204 feature_norm=22.77\n",
      "Iter 18  time=0.03  loss=7805.75  active=103699 feature_norm=24.58\n",
      "Iter 19  time=0.03  loss=7167.46  active=99459 feature_norm=27.33\n",
      "Iter 20  time=0.03  loss=6697.46  active=93649 feature_norm=30.38\n",
      "Iter 21  time=0.03  loss=6319.43  active=89786 feature_norm=32.39\n",
      "Iter 22  time=0.03  loss=5955.32  active=78933 feature_norm=35.09\n",
      "Iter 23  time=0.05  loss=5827.63  active=69391 feature_norm=40.96\n",
      "Iter 24  time=0.03  loss=5270.48  active=67873 feature_norm=42.93\n",
      "Iter 25  time=0.03  loss=5096.52  active=67375 feature_norm=44.71\n",
      "Iter 26  time=0.03  loss=4857.09  active=65843 feature_norm=47.55\n",
      "Iter 27  time=0.03  loss=4582.23  active=58263 feature_norm=51.90\n",
      "Iter 28  time=0.03  loss=4398.56  active=56924 feature_norm=53.87\n",
      "Iter 29  time=0.03  loss=4261.85  active=56270 feature_norm=55.81\n",
      "Iter 30  time=0.03  loss=4052.39  active=54874 feature_norm=58.69\n",
      "Iter 31  time=0.03  loss=3923.19  active=52701 feature_norm=60.64\n",
      "Iter 32  time=0.03  loss=3815.52  active=51948 feature_norm=62.00\n",
      "Iter 33  time=0.03  loss=3696.85  active=49009 feature_norm=63.83\n",
      "Iter 34  time=0.07  loss=3671.17  active=46518 feature_norm=64.63\n",
      "Iter 35  time=0.03  loss=3565.64  active=42258 feature_norm=67.03\n",
      "Iter 36  time=0.03  loss=3508.00  active=41388 feature_norm=68.18\n",
      "Iter 37  time=0.03  loss=3450.32  active=38231 feature_norm=69.57\n",
      "Iter 38  time=0.03  loss=3383.78  active=36864 feature_norm=71.36\n",
      "Iter 39  time=0.03  loss=3347.40  active=35644 feature_norm=72.44\n",
      "Iter 40  time=0.03  loss=3311.10  active=34974 feature_norm=73.27\n",
      "Iter 41  time=0.03  loss=3266.22  active=32885 feature_norm=75.14\n",
      "Iter 42  time=0.03  loss=3237.58  active=31483 feature_norm=76.16\n",
      "Iter 43  time=0.03  loss=3211.78  active=30468 feature_norm=77.49\n",
      "Iter 44  time=0.03  loss=3186.65  active=29060 feature_norm=78.73\n",
      "Iter 45  time=0.03  loss=3166.87  active=28363 feature_norm=79.95\n",
      "Iter 46  time=0.03  loss=3150.15  active=27502 feature_norm=80.93\n",
      "Iter 47  time=0.03  loss=3134.76  active=26880 feature_norm=81.78\n",
      "Iter 48  time=0.03  loss=3119.47  active=25915 feature_norm=82.61\n",
      "Iter 49  time=0.03  loss=3107.92  active=25293 feature_norm=83.44\n",
      "Iter 50  time=0.03  loss=3097.17  active=24976 feature_norm=83.90\n",
      "Iter 51  time=0.03  loss=3087.65  active=24415 feature_norm=84.37\n",
      "Iter 52  time=0.03  loss=3076.81  active=23889 feature_norm=84.65\n",
      "Iter 53  time=0.03  loss=3067.27  active=23332 feature_norm=85.00\n",
      "Iter 54  time=0.03  loss=3058.97  active=22971 feature_norm=85.18\n",
      "Iter 55  time=0.03  loss=3051.69  active=22691 feature_norm=85.28\n",
      "Iter 56  time=0.03  loss=3043.88  active=22349 feature_norm=85.25\n",
      "Iter 57  time=0.03  loss=3035.42  active=21814 feature_norm=85.19\n",
      "Iter 58  time=0.03  loss=3028.73  active=21511 feature_norm=85.14\n",
      "Iter 59  time=0.03  loss=3022.29  active=21251 feature_norm=85.16\n",
      "Iter 60  time=0.03  loss=3015.93  active=20899 feature_norm=85.11\n",
      "Iter 61  time=0.03  loss=3007.90  active=20474 feature_norm=85.08\n",
      "Iter 62  time=0.03  loss=3001.43  active=20194 feature_norm=85.06\n",
      "Iter 63  time=0.03  loss=2996.17  active=20061 feature_norm=85.11\n",
      "Iter 64  time=0.03  loss=2991.51  active=19904 feature_norm=85.14\n",
      "Iter 65  time=0.03  loss=2987.07  active=19660 feature_norm=85.20\n",
      "Iter 66  time=0.03  loss=2982.33  active=19462 feature_norm=85.25\n",
      "Iter 67  time=0.03  loss=2978.14  active=19229 feature_norm=85.32\n",
      "Iter 68  time=0.03  loss=2973.91  active=19089 feature_norm=85.38\n",
      "Iter 69  time=0.03  loss=2970.04  active=18902 feature_norm=85.49\n",
      "Iter 70  time=0.03  loss=2966.08  active=18786 feature_norm=85.57\n",
      "Iter 71  time=0.03  loss=2962.80  active=18711 feature_norm=85.70\n",
      "Iter 72  time=0.03  loss=2959.53  active=18616 feature_norm=85.79\n",
      "Iter 73  time=0.03  loss=2956.63  active=18505 feature_norm=85.91\n",
      "Iter 74  time=0.03  loss=2953.53  active=18338 feature_norm=86.01\n",
      "Iter 75  time=0.03  loss=2951.08  active=18184 feature_norm=86.13\n",
      "Iter 76  time=0.03  loss=2948.48  active=18046 feature_norm=86.22\n",
      "Iter 77  time=0.03  loss=2946.21  active=17962 feature_norm=86.32\n",
      "Iter 78  time=0.03  loss=2943.80  active=17839 feature_norm=86.39\n",
      "Iter 79  time=0.03  loss=2941.31  active=17665 feature_norm=86.52\n",
      "Iter 80  time=0.03  loss=2939.39  active=17557 feature_norm=86.61\n",
      "Iter 81  time=0.03  loss=2937.18  active=17497 feature_norm=86.73\n",
      "Iter 82  time=0.03  loss=2935.37  active=17409 feature_norm=86.79\n",
      "Iter 83  time=0.03  loss=2933.53  active=17277 feature_norm=86.88\n",
      "Iter 84  time=0.03  loss=2931.29  active=17115 feature_norm=86.96\n",
      "Iter 85  time=0.03  loss=2930.04  active=16968 feature_norm=87.12\n",
      "Iter 86  time=0.03  loss=2927.77  active=16879 feature_norm=87.20\n",
      "Iter 87  time=0.03  loss=2925.94  active=16822 feature_norm=87.32\n",
      "Iter 88  time=0.03  loss=2924.40  active=16786 feature_norm=87.35\n",
      "Iter 89  time=0.03  loss=2922.93  active=16687 feature_norm=87.42\n",
      "Iter 90  time=0.03  loss=2921.45  active=16586 feature_norm=87.48\n",
      "Iter 91  time=0.03  loss=2919.97  active=16463 feature_norm=87.58\n",
      "Iter 92  time=0.03  loss=2918.30  active=16414 feature_norm=87.63\n",
      "Iter 93  time=0.03  loss=2917.03  active=16393 feature_norm=87.73\n",
      "Iter 94  time=0.03  loss=2915.67  active=16348 feature_norm=87.77\n",
      "Iter 95  time=0.03  loss=2914.59  active=16289 feature_norm=87.85\n",
      "Iter 96  time=0.03  loss=2913.58  active=16214 feature_norm=87.91\n",
      "Iter 97  time=0.03  loss=2912.12  active=16180 feature_norm=88.03\n",
      "Iter 98  time=0.03  loss=2911.08  active=16175 feature_norm=88.09\n",
      "Iter 99  time=0.03  loss=2909.91  active=16156 feature_norm=88.19\n",
      "Iter 100 time=0.03  loss=2908.96  active=16074 feature_norm=88.25\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 2.998\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 16074 (136895)\n",
      "Number of active attributes: 12323 (122003)\n",
      "Number of active labels: 3 (3)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.023\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.25, c2=0.018,\n",
       "    keep_tempfiles=None, max_iterations=100, verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **表示该位置接受任意多个关键字（keyword）参数，在函数**位置上转化为词典 [key:value, key:value ]\n",
    "crf_model = sklearn_crfsuite.CRF(algorithm='lbfgs',c1=0.25,c2=0.018,max_iterations=100,\n",
    "                                 all_possible_transitions=True,verbose=True)\n",
    "crf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5534f458-44dc-4777-bce4-58c2e701d9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-NOUN      0.994     0.991     0.993      7496\n",
      "      I-NOUN      0.992     0.998     0.995     21526\n",
      "\n",
      "   micro avg      0.993     0.996     0.994     29022\n",
      "   macro avg      0.993     0.994     0.994     29022\n",
      "weighted avg      0.993     0.996     0.994     29022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels=list(crf_model.classes_)\n",
    "labels.remove(\"O\")\n",
    "y_pred = crf_model.predict(X_dev)\n",
    "metrics.flat_f1_score(y_dev, y_pred,\n",
    "                      average='weighted', labels=labels)\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0]))\n",
    "print(metrics.flat_classification_report(\n",
    "    y_dev, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537402be-68c9-4ac5-b9f1-9161666ce10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./chinese_crf_model.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(crf_model, \"./chinese_crf_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5708d24-5b83-4b55-84ad-0d9d9a3b6ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('有', 'O'),\n",
       " ('哪', 'O'),\n",
       " ('些', 'O'),\n",
       " ('公', 'B-NOUN'),\n",
       " ('司', 'I-NOUN'),\n",
       " ('有', 'O'),\n",
       " ('哪', 'O'),\n",
       " ('些', 'O'),\n",
       " ('上', 'B-NOUN'),\n",
       " ('市', 'I-NOUN'),\n",
       " ('公', 'I-NOUN'),\n",
       " ('司', 'I-NOUN'),\n",
       " ('持', 'O'),\n",
       " ('有', 'O'),\n",
       " ('石', 'B-NOUN'),\n",
       " ('药', 'I-NOUN'),\n",
       " ('集', 'I-NOUN'),\n",
       " ('团', 'I-NOUN'),\n",
       " ('的', 'O'),\n",
       " ('股', 'B-NOUN'),\n",
       " ('份', 'I-NOUN')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '有哪些公司有哪些上市公司持有石药集团的股份'\n",
    "\n",
    "NER_tagger = joblib.load('./chinese_crf_model.joblib')\n",
    "list_result = []\n",
    "new_sents = re.split(u'(。|！|\\!|？|\\?)', text)\n",
    "sents_feature = [sent2features(sent) for sent in new_sents]\n",
    "y_pred = NER_tagger.predict(sents_feature)\n",
    "for sent, ner_tag in zip(new_sents, y_pred):\n",
    "    for word, tag in zip(sent, ner_tag):\n",
    "        list_result.append((word,tag))\n",
    "list_result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed5ed934-e283-4e65-af17-0876ebed98a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd5e8a89-8378-4d1f-80e7-2ac523abc406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b46e078-f32e-4767-8fde-6081ddf8d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bulid_result_line(sentence, tag_pred):\n",
    "    result_list = []\n",
    "    for index, tag in zip(range(len(tag_pred)), tag_pred):\n",
    "        if tag[0] == 'B':\n",
    "            start = index\n",
    "            end = index\n",
    "            label_type = tag[2:]\n",
    "            if end != len(tag_pred) - 1:\n",
    "                while tag_pred[end + 1][0] == 'I' and tag_pred[end + 1][2:] == label_type:\n",
    "                    end += 1\n",
    "                    if end == len(tag_pred) - 1:\n",
    "                        break\n",
    "            result_list.append({'start': start,\n",
    "                                'end': end,\n",
    "                                'lable_type': label_type\n",
    "\n",
    "                                })\n",
    "    nouns = []\n",
    "    line = ''.join(sentence)\n",
    "    if len(result_list) != 0:\n",
    "        for index, item in enumerate(result_list):\n",
    "            nouns.append(''.join(sentence[result_list[index]['start']:result_list[index]['end'] + 1]))\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b518346-6652-49f1-9d15-9edb0b3a30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_table('data/test_a/span_extrace_test_A.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "805217b7-3ef0-4cea-a698-e7cfef58713a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>用户问句</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>缩倍量阴是什么情况</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>缩量高换手是什么意思</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>缩量和放量是什么意思</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>缩量十字星说明什么</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>缩量涨停意义</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>有疑似庄股的个股</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>有异动语音播报吗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>有游资的股票和庄股有什么区别</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>有有哪些股票是庄股</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>有在香港上市</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1155 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                用户问句\n",
       "0          缩倍量阴是什么情况\n",
       "1         缩量高换手是什么意思\n",
       "2         缩量和放量是什么意思\n",
       "3          缩量十字星说明什么\n",
       "4             缩量涨停意义\n",
       "...              ...\n",
       "1150        有疑似庄股的个股\n",
       "1151        有异动语音播报吗\n",
       "1152  有游资的股票和庄股有什么区别\n",
       "1153       有有哪些股票是庄股\n",
       "1154          有在香港上市\n",
       "\n",
       "[1155 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0670d093-f8a2-4280-8952-155e2316b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = '有哪些公司有哪些上市公司持有石药集团的股份'\n",
    "\n",
    "NER_tagger = joblib.load('./chinese_crf_model.joblib')\n",
    "list_result = []\n",
    "# new_sents = re.split(u'(。|！|\\!|？|\\?)', text)\n",
    "res_tags=[]\n",
    "for text in test['用户问句']:\n",
    "    new_sents = re.split(u'(。|！|\\!|？|\\?)', text)\n",
    "    sents_feature = [sent2features(sent) for sent in new_sents]\n",
    "    y_pred = NER_tagger.predict(sents_feature)\n",
    "    res_tags.append(y_pred[0])\n",
    "# for sent, ner_tag in zip(new_sents, y_pred):\n",
    "#     for word, tag in zip(sent, ner_tag):\n",
    "#         list_result.append((word,tag))\n",
    "# list_result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a9ccc18-1368-4ae5-af80-fbe665d9a4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['缩倍量阴']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bulid_result_line(test['用户问句'][0],res_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffb28ec5-75c9-46e3-b12f-e66b6ebe0a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'缩倍量阴是什么情况'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['用户问句'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe701f97-7778-4cb7-ad3d-4da263aeb7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-NOUN', 'I-NOUN', 'I-NOUN', 'I-NOUN', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1f99d84-1672-434b-a18f-6ea1c021d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "\n",
    "\n",
    "for text,tags in zip(test['用户问句'],res_tags):\n",
    "    results.append('_|_'.join(_bulid_result_line(text,tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63df4b51-1b49-40ec-adde-44082895116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['名词短语']=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bd964dc-bc47-4e84-8d59-8f466496644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('result.txt', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d53b02-0236-41c5-ba3b-c1378d4bb064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
